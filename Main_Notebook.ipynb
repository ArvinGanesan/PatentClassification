{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qs\n",
    "- Do we have year, to split train / test by year? \n",
    "- what did we do for patents with multiple documents ?\n",
    "- word-embeddings (train our own or use pre-trained ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import gzip\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Embedding, Reshape, Flatten, Conv1D, Conv2D, MaxPool2D, GlobalMaxPool1D, SpatialDropout1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from keras import optimizers, models\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "\n",
    "# features \n",
    "current_dir = %pwd\n",
    "abstract = pd.read_table(current_dir+'/out_zipped/docNumberToAbsText.txt.gz',compression='gzip',\n",
    "                         sep='|', names = ['doc_num', 'abstract'], header=None)\n",
    "claim = pd.read_table(current_dir+'/out_zipped/docNumberToClaimText.txt.gz',compression='gzip',\n",
    "                         sep='|', names = ['doc_num', 'claim'], header=None)\n",
    "desc = pd.read_table(current_dir+'/out_zipped/docNumberToDescText.txt.gz',compression='gzip',\n",
    "                         sep='|', names = ['doc_num', 'desc'], header=None)\n",
    "title = pd.read_table(current_dir+'/out_zipped/docNumberToInvTitle.txt.gz',compression='gzip',\n",
    "                         sep='|', names = ['doc_num', 'title'], header=None)\n",
    "file_name = pd.read_table(current_dir+'/out_zipped/fileNameToDocNumber.txt.gz',compression='gzip',\n",
    "                         sep='|', names = ['file_name', 'doc_num'], header=None)\n",
    "\n",
    "# labels \n",
    "labels = pd.read_table(current_dir+'/out_zipped/docNumberToLabelSubClass.txt.gz',compression='gzip', header=None)\n",
    "labels = labels[0].str.split('|', expand=True).rename(columns={0:'doc_num'})\n",
    "clas = pd.read_table(current_dir+'/out_zipped/docNumberToClassText.txt.gz',compression='gzip', header=None)\n",
    "clas = clas[0].str.split('|', expand=True).rename(columns={0:'doc_num'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4)\n",
      "(25000, 14)\n"
     ]
    }
   ],
   "source": [
    "# joining the datasets using outer join, NOT removing the patents that are missing sections\n",
    "# DISCUSSION: should we change it to inner join (i.e. removing the patents that are missing sections)\n",
    "X = pd.concat([title.set_index('doc_num'), \n",
    "           abstract.set_index('doc_num'), \n",
    "           claim.set_index('doc_num'), \n",
    "           desc.set_index('doc_num')], axis=1).sort_index() #  join='inner'\n",
    "\n",
    "Y = labels.set_index('doc_num').sort_index().set_index(X.index) # fixing the index mismatch\n",
    "Y.columns=[\"label{}\".format(i) for i in range(1,15)] # renaming columns \n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835 documents with null title\n",
      "0 documents with null claims\n",
      "58 documents with null abstract\n",
      "0 documents with null description\n"
     ]
    }
   ],
   "source": [
    "# data cleaning \n",
    "assert Y['label1'].isnull().sum() == 0 # there is no document with \n",
    "\n",
    "print(\"{} documents with null title\".format(X['title'].isnull().sum()))\n",
    "print(\"{} documents with null claims\".format(X['claim'].isnull().sum()))\n",
    "print(\"{} documents with null abstract\".format(X['abstract'].isnull().sum()))\n",
    "print(\"{} documents with null description\".format(X['desc'].isnull().sum()))\n",
    "\n",
    "# remove documents with null sections (title and abstract)\n",
    "X_clean = X.dropna(how='any')\n",
    "null_idx = X[~X.index.isin(X_clean.index)].index # storing the removed indices (i.e. document numbers)\n",
    "assert X.shape[0] - null_idx.shape[0] == X_clean.shape[0] # making sure the row counts match\n",
    "\n",
    "# removing the documents with null sections from the labels as well \n",
    "Y_clean = Y.loc[X_clean.index]\n",
    "\n",
    "# some checks\n",
    "assert X_clean.shape[0] == Y_clean.shape[0]\n",
    "assert ((Y_clean.index == X_clean.index)*1).sum() == X_clean.shape[0]\n",
    "\n",
    "# lower casing everything\n",
    "X_clean = X_clean.apply(lambda x: x.str.lower())\n",
    "Y_clean = Y_clean.apply(lambda x: x.str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data set \n",
    "# in this first pass we will concat the text of all patent sections \n",
    "# for labels we will use the first label only \n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['full_text'] = X_clean['title'] + \" \" + X_clean['claim'] + \" \" + X_clean['abstract'] + \" \" + X_clean['desc']\n",
    "data['label1'] = Y_clean['label1']\n",
    "\n",
    "#data.full_text[100005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100005</th>\n",
       "      <td>image downsampling using redundant pixel remov...</td>\n",
       "      <td>image data processing or generation, in general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100008</th>\n",
       "      <td>electric power variation compensating device a...</td>\n",
       "      <td>wind motors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>die for tubular film extrusion a die for the e...</td>\n",
       "      <td>shaping or joining of plastics; shaping of sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100010</th>\n",
       "      <td>stencil printer a stencil printer comprising: ...</td>\n",
       "      <td>apparatus or devices for manifolding, duplicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100018</th>\n",
       "      <td>system containing a plurality of drams and a b...</td>\n",
       "      <td>electric digital data processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100023</th>\n",
       "      <td>a method of manufacturing coverings and a cove...</td>\n",
       "      <td>shaping or joining of plastics; shaping of sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100027</th>\n",
       "      <td>high-frequency switch a high-frequency switch ...</td>\n",
       "      <td>transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028</th>\n",
       "      <td>a dual mode drum brake device a dual mode drum...</td>\n",
       "      <td>couplings for transmitting rotation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100029</th>\n",
       "      <td>information recording medium an information re...</td>\n",
       "      <td>materials for applications not otherwise provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100030</th>\n",
       "      <td>fiber-optic gyro utilizing pseudorandom-bit-se...</td>\n",
       "      <td>measuring distances, levels or bearings; surve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100031</th>\n",
       "      <td>computationally parsimonious forward link rece...</td>\n",
       "      <td>transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100039</th>\n",
       "      <td>catalyst for purifying exhaust gas a catalyst ...</td>\n",
       "      <td>chemical or physical processes, e.g. catalysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100040</th>\n",
       "      <td>microscope a microscope comprising a support s...</td>\n",
       "      <td>optical elements, systems, or apparatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100042</th>\n",
       "      <td>integral positioning and imaging device an ima...</td>\n",
       "      <td>image data processing or generation, in general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100043</th>\n",
       "      <td>paper level determination a method of determin...</td>\n",
       "      <td>counting mechanisms; counting of objects not o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100049</th>\n",
       "      <td>improved electromagnetic actuator for washing ...</td>\n",
       "      <td>magnets; inductances; transformers; selection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100051</th>\n",
       "      <td>process for producing non-contact data carrier...</td>\n",
       "      <td>recognition of data; presentation of data; rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100053</th>\n",
       "      <td>header for milking units with a flow adjuster ...</td>\n",
       "      <td>manufacture of dairy products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100054</th>\n",
       "      <td>method and apparatus for the reproduction of m...</td>\n",
       "      <td>stereophonic systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100069</th>\n",
       "      <td>vehicle control apparatus and method sharing c...</td>\n",
       "      <td>control or regulating systems in general; func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100075</th>\n",
       "      <td>nozzle for hydrostatic forming and hydrostatic...</td>\n",
       "      <td>spraying apparatus; atomising apparatus; nozzles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100076</th>\n",
       "      <td>device for removing a wire harness from a vehi...</td>\n",
       "      <td>electrically-conductive connections; structura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100077</th>\n",
       "      <td>dynamically expandable storage unit array syst...</td>\n",
       "      <td>electric digital data processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100079</th>\n",
       "      <td>method for manufacturing a resin molded assemb...</td>\n",
       "      <td>shaping or joining of plastics; shaping of sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100080</th>\n",
       "      <td>rolling bearing a rolling bearing comprising: ...</td>\n",
       "      <td>shafts; flexible shafts; mechanical means for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100081</th>\n",
       "      <td>method for enhancing activity to regenerate el...</td>\n",
       "      <td>fermentation or enzyme-using processes to synt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100083</th>\n",
       "      <td>vector for introducing a gene into a plant usi...</td>\n",
       "      <td>peptides</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100084</th>\n",
       "      <td>vertical bipolar transistor and method of manu...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100085</th>\n",
       "      <td>semiconductor laser and method of manufacturin...</td>\n",
       "      <td>devices using stimulated emission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100086</th>\n",
       "      <td>an advertising standard system an advertising ...</td>\n",
       "      <td>displaying; advertising; signs; labels or name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973210</th>\n",
       "      <td>information providing device and method an inf...</td>\n",
       "      <td>electric digital data processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973211</th>\n",
       "      <td>information providing device and method an inf...</td>\n",
       "      <td>electric digital data processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973216</th>\n",
       "      <td>speaker device a speaker apparatus comprising:...</td>\n",
       "      <td>loudspeakers, microphones, gramophone pick-ups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973264</th>\n",
       "      <td>catalyst for hydrofining and method for prepar...</td>\n",
       "      <td>chemical or physical processes, e.g. catalysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973266</th>\n",
       "      <td>molding powder for continuous casting of steel...</td>\n",
       "      <td>casting of metals; casting of other substances...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973272</th>\n",
       "      <td>ink-jet head, ink-jet printer, and its driving...</td>\n",
       "      <td>typewriters; selective printing mechanisms, i....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973298</th>\n",
       "      <td>process for producing modified phenolic resin ...</td>\n",
       "      <td>macromolecular compounds obtained otherwise th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973305</th>\n",
       "      <td>method for isomerization of hydrocarbon, and s...</td>\n",
       "      <td>chemical or physical processes, e.g. catalysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973310</th>\n",
       "      <td>high strength cold rolled steel plate and meth...</td>\n",
       "      <td>alloys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973311</th>\n",
       "      <td>silicon wafer and method of manufacture thereo...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973320</th>\n",
       "      <td>rotary damper a rotary damper comprising a cas...</td>\n",
       "      <td>devices for moving wings into open or closed p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973325</th>\n",
       "      <td>semiconductor pressure sensor and its manufact...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973331</th>\n",
       "      <td>arrayed waveguide grating multiplexer and demu...</td>\n",
       "      <td>optical elements, systems, or apparatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973341</th>\n",
       "      <td>optical recording medium, recorder for optical...</td>\n",
       "      <td>information storage based on relative movement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973349</th>\n",
       "      <td>method and apparatus for processing wafer a su...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973352</th>\n",
       "      <td>rf circuit module an rf circuit module compris...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973360</th>\n",
       "      <td>electronic device, electronic timepiece and po...</td>\n",
       "      <td>electromechanical clocks or watches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973367</th>\n",
       "      <td>method and apparatus for network control a net...</td>\n",
       "      <td>transmission of digital information, e.g. tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973368</th>\n",
       "      <td>channel check test system a channel check test...</td>\n",
       "      <td>transmission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973369</th>\n",
       "      <td>serial digital interface system transmission/r...</td>\n",
       "      <td>pictorial communication, e.g. television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973370</th>\n",
       "      <td>traffic control method for mobile data communi...</td>\n",
       "      <td>wireless communication networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973406</th>\n",
       "      <td>light-weight cellular concrete with excellent ...</td>\n",
       "      <td>lime; magnesia; slag; cements; compositions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973429</th>\n",
       "      <td>image processor for observing optical fiber an...</td>\n",
       "      <td>optical elements, systems, or apparatus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973438</th>\n",
       "      <td>ac plasma display panel an ac type plasma disp...</td>\n",
       "      <td>arrangements or circuits for control of indica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973470</th>\n",
       "      <td>deodorant composition a deodorant composition ...</td>\n",
       "      <td>methods or apparatus for sterilising materials...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973572</th>\n",
       "      <td>medical pressure-sensitive adhesive tape a med...</td>\n",
       "      <td>filters implantable into blood vessels; prosth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973573</th>\n",
       "      <td>metal sheet bending device the apparatus for b...</td>\n",
       "      <td>working or processing of sheet metal or metal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973580</th>\n",
       "      <td>method for producing single crystal and pullin...</td>\n",
       "      <td>single-crystal growth ; apparatus therefor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973592</th>\n",
       "      <td>light emitting diode and its manufacturing met...</td>\n",
       "      <td>semiconductor devices; electric solid state de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973593</th>\n",
       "      <td>material of positive plate for lithium seconda...</td>\n",
       "      <td>processes or means, e.g. batteries, for the di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  full_text  \\\n",
       "doc_num                                                       \n",
       "100005    image downsampling using redundant pixel remov...   \n",
       "100008    electric power variation compensating device a...   \n",
       "100009    die for tubular film extrusion a die for the e...   \n",
       "100010    stencil printer a stencil printer comprising: ...   \n",
       "100018    system containing a plurality of drams and a b...   \n",
       "100023    a method of manufacturing coverings and a cove...   \n",
       "100027    high-frequency switch a high-frequency switch ...   \n",
       "100028    a dual mode drum brake device a dual mode drum...   \n",
       "100029    information recording medium an information re...   \n",
       "100030    fiber-optic gyro utilizing pseudorandom-bit-se...   \n",
       "100031    computationally parsimonious forward link rece...   \n",
       "100039    catalyst for purifying exhaust gas a catalyst ...   \n",
       "100040    microscope a microscope comprising a support s...   \n",
       "100042    integral positioning and imaging device an ima...   \n",
       "100043    paper level determination a method of determin...   \n",
       "100049    improved electromagnetic actuator for washing ...   \n",
       "100051    process for producing non-contact data carrier...   \n",
       "100053    header for milking units with a flow adjuster ...   \n",
       "100054    method and apparatus for the reproduction of m...   \n",
       "100069    vehicle control apparatus and method sharing c...   \n",
       "100075    nozzle for hydrostatic forming and hydrostatic...   \n",
       "100076    device for removing a wire harness from a vehi...   \n",
       "100077    dynamically expandable storage unit array syst...   \n",
       "100079    method for manufacturing a resin molded assemb...   \n",
       "100080    rolling bearing a rolling bearing comprising: ...   \n",
       "100081    method for enhancing activity to regenerate el...   \n",
       "100083    vector for introducing a gene into a plant usi...   \n",
       "100084    vertical bipolar transistor and method of manu...   \n",
       "100085    semiconductor laser and method of manufacturin...   \n",
       "100086    an advertising standard system an advertising ...   \n",
       "...                                                     ...   \n",
       "99973210  information providing device and method an inf...   \n",
       "99973211  information providing device and method an inf...   \n",
       "99973216  speaker device a speaker apparatus comprising:...   \n",
       "99973264  catalyst for hydrofining and method for prepar...   \n",
       "99973266  molding powder for continuous casting of steel...   \n",
       "99973272  ink-jet head, ink-jet printer, and its driving...   \n",
       "99973298  process for producing modified phenolic resin ...   \n",
       "99973305  method for isomerization of hydrocarbon, and s...   \n",
       "99973310  high strength cold rolled steel plate and meth...   \n",
       "99973311  silicon wafer and method of manufacture thereo...   \n",
       "99973320  rotary damper a rotary damper comprising a cas...   \n",
       "99973325  semiconductor pressure sensor and its manufact...   \n",
       "99973331  arrayed waveguide grating multiplexer and demu...   \n",
       "99973341  optical recording medium, recorder for optical...   \n",
       "99973349  method and apparatus for processing wafer a su...   \n",
       "99973352  rf circuit module an rf circuit module compris...   \n",
       "99973360  electronic device, electronic timepiece and po...   \n",
       "99973367  method and apparatus for network control a net...   \n",
       "99973368  channel check test system a channel check test...   \n",
       "99973369  serial digital interface system transmission/r...   \n",
       "99973370  traffic control method for mobile data communi...   \n",
       "99973406  light-weight cellular concrete with excellent ...   \n",
       "99973429  image processor for observing optical fiber an...   \n",
       "99973438  ac plasma display panel an ac type plasma disp...   \n",
       "99973470  deodorant composition a deodorant composition ...   \n",
       "99973572  medical pressure-sensitive adhesive tape a med...   \n",
       "99973573  metal sheet bending device the apparatus for b...   \n",
       "99973580  method for producing single crystal and pullin...   \n",
       "99973592  light emitting diode and its manufacturing met...   \n",
       "99973593  material of positive plate for lithium seconda...   \n",
       "\n",
       "                                                     label1  \n",
       "doc_num                                                      \n",
       "100005     image data processing or generation, in general   \n",
       "100008                                          wind motors  \n",
       "100009    shaping or joining of plastics; shaping of sub...  \n",
       "100010    apparatus or devices for manifolding, duplicat...  \n",
       "100018                    electric digital data processing   \n",
       "100023    shaping or joining of plastics; shaping of sub...  \n",
       "100027                                        transmission   \n",
       "100028                 couplings for transmitting rotation   \n",
       "100029    materials for applications not otherwise provi...  \n",
       "100030    measuring distances, levels or bearings; surve...  \n",
       "100031                                        transmission   \n",
       "100039    chemical or physical processes, e.g. catalysis...  \n",
       "100040             optical elements, systems, or apparatus   \n",
       "100042     image data processing or generation, in general   \n",
       "100043    counting mechanisms; counting of objects not o...  \n",
       "100049    magnets; inductances; transformers; selection ...  \n",
       "100051    recognition of data; presentation of data; rec...  \n",
       "100053                       manufacture of dairy products   \n",
       "100054                                stereophonic systems   \n",
       "100069    control or regulating systems in general; func...  \n",
       "100075    spraying apparatus; atomising apparatus; nozzles   \n",
       "100076    electrically-conductive connections; structura...  \n",
       "100077                    electric digital data processing   \n",
       "100079    shaping or joining of plastics; shaping of sub...  \n",
       "100080    shafts; flexible shafts; mechanical means for ...  \n",
       "100081    fermentation or enzyme-using processes to synt...  \n",
       "100083                                            peptides   \n",
       "100084    semiconductor devices; electric solid state de...  \n",
       "100085                    devices using stimulated emission  \n",
       "100086    displaying; advertising; signs; labels or name...  \n",
       "...                                                     ...  \n",
       "99973210                  electric digital data processing   \n",
       "99973211                  electric digital data processing   \n",
       "99973216  loudspeakers, microphones, gramophone pick-ups...  \n",
       "99973264  chemical or physical processes, e.g. catalysis...  \n",
       "99973266  casting of metals; casting of other substances...  \n",
       "99973272  typewriters; selective printing mechanisms, i....  \n",
       "99973298  macromolecular compounds obtained otherwise th...  \n",
       "99973305  chemical or physical processes, e.g. catalysis...  \n",
       "99973310                                            alloys   \n",
       "99973311  semiconductor devices; electric solid state de...  \n",
       "99973320  devices for moving wings into open or closed p...  \n",
       "99973325  semiconductor devices; electric solid state de...  \n",
       "99973331           optical elements, systems, or apparatus   \n",
       "99973341  information storage based on relative movement...  \n",
       "99973349  semiconductor devices; electric solid state de...  \n",
       "99973352  semiconductor devices; electric solid state de...  \n",
       "99973360               electromechanical clocks or watches   \n",
       "99973367  transmission of digital information, e.g. tele...  \n",
       "99973368                                      transmission   \n",
       "99973369           pictorial communication, e.g. television  \n",
       "99973370                    wireless communication networks  \n",
       "99973406  lime; magnesia; slag; cements; compositions th...  \n",
       "99973429           optical elements, systems, or apparatus   \n",
       "99973438  arrangements or circuits for control of indica...  \n",
       "99973470  methods or apparatus for sterilising materials...  \n",
       "99973572  filters implantable into blood vessels; prosth...  \n",
       "99973573  working or processing of sheet metal or metal ...  \n",
       "99973580         single-crystal growth ; apparatus therefor  \n",
       "99973592  semiconductor devices; electric solid state de...  \n",
       "99973593  processes or means, e.g. batteries, for the di...  \n",
       "\n",
       "[23108 rows x 2 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average document length: 2560 words\n",
      "Median document length: 2580.0 words\n",
      "Max document length: 126735 words\n",
      "Min document length: 1056 words\n"
     ]
    }
   ],
   "source": [
    "# examing the document length \n",
    "doc_lenghts = data.full_text.str.len()\n",
    "print(\"Average document length: {} words\".format(round(np.mean(doc_lenghts))))\n",
    "print(\"Median document length: {} words\".format(round(np.median(doc_lenghts))))\n",
    "print(\"Max document length: {} words\".format(round(np.max(doc_lenghts))))\n",
    "print(\"Min document length: {} words\".format(round(np.min(doc_lenghts))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18486,)\n",
      "(4622,)\n",
      "(18486,)\n",
      "(4622,)\n"
     ]
    }
   ],
   "source": [
    "# train test split \n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(data['full_text'], data['label1'], test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.fit_transform(Y_test)\n",
    "\n",
    "#pd.Series(Y_train).value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sequence length is set to median document length\n",
    "sequence_length = 2580\n",
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word-embeddings: representing documents using a dense vector representation\n",
    "# Word embeddings can be trained using the input corpus itself or \n",
    "# can be generated using pre-trained word embeddings such as Glove, FastText, and Word2Vec\n",
    "\n",
    "# step 1. Loading the pretrained word embeddings\n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('pretrained_word_embeddings/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 2. Creating a tokenizer object using Keras preprocessing object \n",
    "# the tokenizer has a default filter that removes all punctuation, plus tabs and line breaks, minus the ' character.\n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(data['full_text'])\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in our vocabulary: 71451\n"
     ]
    }
   ],
   "source": [
    "print('Number of words in our vocabulary: {}'.format(len(word_index.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step 3. Transforming text documents to sequence of tokens and padding them to ensure equal length vectors\n",
    "# choosing the median document length as max length for padding \n",
    "X_train_seq = sequence.pad_sequences(token.texts_to_sequences(X_train), maxlen=sequence_length)\n",
    "X_test_seq = sequence.pad_sequences(token.texts_to_sequences(X_test), maxlen=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18486, 2580)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4. Creating a mapping of tokens and their respective embeddings\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71452, 300)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18486, 2580)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters \n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "vocabulary_size = len(word_index) + 1\n",
    "sequence_length = sequence_length\n",
    "embedding_dim = embedding_dim\n",
    "num_filters = 100\n",
    "kernel_size = 3\n",
    "units = pd.Series(Y_train).value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 2580)              0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 2580, 300)         21435600  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 2580, 300)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 2578, 100)         90100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 532)               27132     \n",
      "=================================================================\n",
      "Total params: 21,557,882\n",
      "Trainable params: 122,282\n",
      "Non-trainable params: 21,435,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input Layer\n",
    "input_layer = Input(shape=(sequence_length,), dtype='int32')\n",
    "\n",
    "# Word embedding Layer\n",
    "embedding_layer = Embedding(input_dim=vocabulary_size, output_dim=embedding_dim, input_length=sequence_length, \n",
    "                            weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "embedding_layer = SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "# Convolutional Layer\n",
    "conv_layer = Conv1D(num_filters, kernel_size=kernel_size, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "# Pooling Layer\n",
    "pooling_layer = GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "# Output Layers\n",
    "output_layer1 = Dense(50, activation=\"relu\")(pooling_layer)\n",
    "output_layer1 = Dropout(0.25)(output_layer1)\n",
    "output_layer2 = Dense(units= units, activation=\"softmax\")(output_layer1)\n",
    "\n",
    "# Compile the model\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer2,)\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-3), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_train).value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18486, 532)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(Y_train)\n",
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16637 samples, validate on 1849 samples\n",
      "Epoch 1/2\n",
      "10720/16637 [==================>...........] - ETA: 2:43 - loss: 5.3612 - acc: 0.0527"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "history = model.fit(X_train_seq, y_binary,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define parameters\n",
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple fully connected layer NN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
